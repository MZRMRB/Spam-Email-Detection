{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *Spam Email Detection\t*\n",
    "\n",
    "# Goal: Build a model to classify emails as spam or non-spam.\n",
    "# Steps:\n",
    "\n",
    "# Frontend: Streamlit.\n",
    "# Dataset: SMS Spam Collection Dataset\n",
    "# Model: Use Logistic Regression, Naive Bayes, or LSTM for text classification.\n",
    "# Evaluation: Precision, recall, and F1-score.\n",
    "\n",
    "# https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp310-cp310-win_amd64.whl (11.1 MB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp310-cp310-win_amd64.whl (7.5 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Collecting tzdata>=2022.7\n",
      "  Using cached tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Collecting pytz>=2020.1\n",
      "  Using cached pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting scipy>=1.6.0\n",
      "  Using cached scipy-1.15.2-cp310-cp310-win_amd64.whl (41.2 MB)\n",
      "Collecting tensorflow-intel==2.18.0\n",
      "  Downloading tensorflow_intel-2.18.0-cp310-cp310-win_amd64.whl (390.0 MB)\n",
      "Collecting h5py>=3.11.0\n",
      "  Downloading h5py-3.13.0-cp310-cp310-win_amd64.whl (3.0 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.17.2-cp310-cp310-win_amd64.whl (38 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "Requirement already satisfied: packaging in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting tensorboard<2.19,>=2.18\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (57.4.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "Collecting flatbuffers>=24.3.25\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0\n",
      "  Using cached ml_dtypes-0.4.1-cp310-cp310-win_amd64.whl (126 kB)\n",
      "Collecting keras>=3.5.0\n",
      "  Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.70.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Collecting rich\n",
      "  Using cached rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Collecting optree\n",
      "  Using cached optree-0.14.0-cp310-cp310-win_amd64.whl (290 kB)\n",
      "Collecting namex\n",
      "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl (102 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-3.0.2-cp310-cp310-win_amd64.whl (15 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, numpy, MarkupSafe, markdown-it-py, wheel, werkzeug, urllib3, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, markdown, idna, h5py, grpcio, charset-normalizer, certifi, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard, requests, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tzdata, threadpoolctl, tensorflow-intel, scipy, pytz, joblib, tensorflow, scikit-learn, pandas\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 idna-3.10 joblib-1.4.2 keras-3.8.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 pandas-2.2.3 protobuf-5.29.3 pytz-2025.1 requests-2.32.3 rich-13.9.4 scikit-learn-1.6.1 scipy-1.15.2 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2025.1 urllib3-2.3.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\FARAZ TRADERS\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn tensorflow numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: keras in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: namex in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: rich in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: absl-py in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (3.13.0)\n",
      "Requirement already satisfied: optree in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (2.0.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\FARAZ TRADERS\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (57.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.13.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: optree in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.14.0)\n",
      "Requirement already satisfied: rich in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\faraz traders\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\faraz traders\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\FARAZ TRADERS\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FARAZ TRADERS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "140/140 - 20s - 143ms/step - accuracy: 0.9569 - loss: 0.1261 - val_accuracy: 0.9848 - val_loss: 0.0588\n",
      "Epoch 2/5\n",
      "140/140 - 12s - 83ms/step - accuracy: 0.9915 - loss: 0.0301 - val_accuracy: 0.9812 - val_loss: 0.0783\n",
      "Epoch 3/5\n",
      "140/140 - 10s - 74ms/step - accuracy: 0.9953 - loss: 0.0177 - val_accuracy: 0.9821 - val_loss: 0.0692\n",
      "Epoch 4/5\n",
      "140/140 - 11s - 76ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9812 - val_loss: 0.0803\n",
      "Epoch 5/5\n",
      "140/140 - 10s - 73ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 0.9821 - val_loss: 0.0822\n",
      "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step\n",
      "\n",
      "=== SPAM DETECTION MODEL RESULTS ===\n",
      "\n",
      "Model: Naïve Bayes\n",
      "Accuracy: 0.9776\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       965\n",
      "           1       1.00      0.83      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "==================================================\n",
      "Model: SVM\n",
      "Accuracy: 0.9794\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.87      0.92       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "==================================================\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9785\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.98      0.85      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "==================================================\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.9632\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       0.97      0.75      0.85       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.97      0.87      0.91      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n",
      "==================================================\n",
      "Model: Deep Learning (LSTM)\n",
      "Accuracy: 0.9821\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.97      0.89      0.93       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.94      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('spam.csv', usecols=[0, 1], names=['label', 'message'], header=0, encoding='latin1')\n",
    "\n",
    "# Preprocessing: Convert labels to binary values (0 for ham, 1 for spam)\n",
    "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Machine Learning Models: Using TF-IDF Vectorization\n",
    "# Create TF-IDF Vectorizer to convert text data into numerical form\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=3000)\n",
    "\n",
    "# Fit and transform the training data, transform the testing data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Standardize for logistic regression\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train_tfidf)\n",
    "X_test_scaled = scaler.transform(X_test_tfidf)\n",
    "\n",
    "# Train ML models\n",
    "models = {\n",
    "    'Naïve Bayes': MultinomialNB(),\n",
    "    'SVM': SVC(kernel='linear', C=1.0),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, solver='liblinear', random_state=42)\n",
    "}\n",
    " \n",
    "# Train and evaluate each machine learning model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    if name == 'Naive Bayes':  # Naive Bayes works directly with sparse matrices\n",
    "        model.fit(X_train_tfidf, y_train)\n",
    "        y_pred = model.predict(X_test_tfidf)\n",
    "    else:  # Other models require dense arrays\n",
    "        model.fit(X_train_tfidf.toarray(), y_train)\n",
    "        y_pred = model.predict(X_test_tfidf.toarray())\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, zero_division=0)\n",
    "    results[name] = {'accuracy': accuracy, 'report': report}\n",
    "\n",
    "# Deep Learning Model: Using LSTM for Sequence Classification\n",
    "# Tokenize messages and pad sequences for deep learning models\n",
    "max_features = 5000  # Maximum number of words to consider\n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(df['message'].values)\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train.values)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test.values)\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_len = 20  # Maximum length of each sequence\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Build an LSTM-based neural network model\n",
    "model = Sequential([\n",
    "        Embedding(max_features, 256, input_length=max_len),\n",
    "        SpatialDropout1D(0.3),\n",
    "        Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ]) # Output layer for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_data=(X_test_pad, y_test), verbose=2)\n",
    "\n",
    "# Evaluate the LSTM model\n",
    "y_pred_dl = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "dl_accuracy = accuracy_score(y_test, y_pred_dl)\n",
    "dl_report = classification_report(y_test, y_pred_dl, zero_division=0)\n",
    "results['Deep Learning (LSTM)'] = {'accuracy': dl_accuracy, 'report': dl_report}\n",
    "\n",
    "# Print results for all models\n",
    "print(\"\\n=== SPAM DETECTION MODEL RESULTS ===\\n\")\n",
    "for model_name, result in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Accuracy: {result['accuracy']:.4f}\")\n",
    "    print(\"Classification Report:\\n\", result['report'])\n",
    "    print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
